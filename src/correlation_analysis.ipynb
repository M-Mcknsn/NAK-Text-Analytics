{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Correlation Analysis\n",
    "*Master \"Applied Data Science\" @ Nordakademie*\n",
    "*Modul: Text Analytics*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### General pre-work"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# Overall needed\n",
    "import pandas as pd # to work with data frames\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Needed for visualisations and smaller functions such as time tracking or saving files\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os # to define a dedicated output folder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "output_folder = 'data/analysis' # refer to a new folder to store only sentiment result files\n",
    "\n",
    "# check if folder can be found, else create it\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Add the normal distribution stock values to the combined sentiment table\n",
    "\n",
    "csv_file_path_normal_3 = 'data/transfer/cleaned_articles_normalverteilt_3.csv' # define the path of the input csv file with 3 categories, normal distribution\n",
    "\n",
    "# Load the data set\n",
    "df_3categories_normal = pd.read_csv(csv_file_path_normal_3, encoding='utf-8', quoting=csv.QUOTE_ALL) # ensuring the right encoding as in the csv file we still encounter incorrectly encoded special characters\n",
    "\n",
    "csv_file_path_combined_sentiments = 'data/sentiment_results/sentiment_results_combined.csv' # define the path of the input csv file with the sentiment results\n",
    "\n",
    "# Load the data set\n",
    "df_combined_sentiments = pd.read_csv(csv_file_path_combined_sentiments, encoding='utf-8', quoting=csv.QUOTE_ALL) # ensuring the right encoding as in the csv file we still encounter incorrectly encoded special characters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-Processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Row_Number                   Unternehmen Newstyp   Quelle Nearest_Date  \\\n",
      "0           1  Porsche Automobil Holding SE    News  onvista   2021-06-01   \n",
      "1           2                    Beiersdorf    News  onvista   2021-06-02   \n",
      "2           3          Heidelberg Materials    News  onvista   2021-06-02   \n",
      "\n",
      "                                        Cleaned_Text Stock_Value  \\\n",
      "0  neu Rumor Porschebörsengang Sixt Berenberg stu...     neutral   \n",
      "1  Beiersdorf Aktie Kaufempfehlung beflügeln Bere...    positive   \n",
      "2  Heidelbergcement klimaneutral Zementwerk Weg B...    positive   \n",
      "\n",
      "   TextBlob_Sentiment_Score TextBlob_Evenly_Separated_Label  \\\n",
      "0                   -0.0500                        Negative   \n",
      "1                    0.2000                        Positive   \n",
      "2                   -0.0875                        Negative   \n",
      "\n",
      "  TextBlob_Normal_Distribution_Label  NLTK_Sentiment  \\\n",
      "0                            Neutral         -0.3612   \n",
      "1                           Positive          0.0000   \n",
      "2                            Neutral         -0.4588   \n",
      "\n",
      "  NLTK_Evenly_Separated_Label NLTK_Normal_Distribution_Label Stock_ValueStd  \n",
      "0                    Negative                        Neutral        neutral  \n",
      "1                     Neutral                        Neutral       positive  \n",
      "2                    Negative                        Neutral        neutral  \n"
     ]
    }
   ],
   "source": [
    "# Merge the two data frames based on a common column, such as an index or a specific column name\n",
    "# In this example, I assume you want to use the index as the merge key\n",
    "df_merged_3_categories = df_combined_sentiments.merge(df_3categories_normal[['Stock_ValueStd']], left_index=True, right_index=True)\n",
    "\n",
    "# Save the merged data frame to a new variable or file if needed\n",
    "# merged_df contains the combined data with the \"Stock_ValueStd\" column added\n",
    "\n",
    "# If you want to save the merged data frame to a new CSV file, you can use the following:\n",
    "# merged_df.to_csv('merged_data.csv', index=False)\n",
    "\n",
    "print(df_merged_3_categories.head(3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "#Rename and reposition columns\n",
    "\n",
    "# 1. Rename column \"Stock_Value\" to \"Stock_Value_evenly_separated\"\n",
    "df_merged_3_categories.rename(columns={'Stock_Value': 'Stock_Value_Evenly_Separated'}, inplace=True)\n",
    "\n",
    "# 2. Rename column \"Stock_ValueStd\" to \"Stock_Value_normal_distribution\"\n",
    "df_merged_3_categories.rename(columns={'Stock_ValueStd': 'Stock_Value_Normal_Distribution'}, inplace=True)\n",
    "\n",
    "# 3. Reorder columns to move \"Stock_Value_normal_distribution\" to the 8th column\n",
    "cols = df_merged_3_categories.columns.tolist()\n",
    "cols.insert(7, cols.pop(cols.index('Stock_Value_Normal_Distribution')))\n",
    "df_merged_3_categories = df_merged_3_categories[cols]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved as data/analysis\\analysis_3_categories.csv and data/analysis\\analysis_3_categories.xlsx.\n"
     ]
    }
   ],
   "source": [
    "# Save the merged file in the correct repository folder\n",
    "\n",
    "# Save to an Excel file\n",
    "excel_output_file_analysis_3 = os.path.join(output_folder, 'analysis_3_categories.xlsx')\n",
    "df_merged_3_categories.to_excel(excel_output_file_analysis_3, index=False)\n",
    "\n",
    "# Save the results to a csv file with the same name\n",
    "csv_output_file_analysis_3 = os.path.join(output_folder, 'analysis_3_categories.csv')\n",
    "df_merged_3_categories.to_csv(csv_output_file_analysis_3, index=False, encoding='utf-8', quoting=csv.QUOTE_ALL)\n",
    "\n",
    "# Print final info\n",
    "print(f\"Results saved as {csv_output_file_analysis_3} and {excel_output_file_analysis_3}.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Correlation Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3 Categories"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### TextBlob Even Separation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Squared Statistic: 74.37817173044427\n",
      "P-Value: 2.6972703877652494e-15\n",
      "There is a significant association between the two categorical variables Stock_Value_Evenly_Separated and TextBlob_Evenly_Separated_Label.\n"
     ]
    }
   ],
   "source": [
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(df_merged_3_categories['Stock_Value_Evenly_Separated'], df_merged_3_categories['TextBlob_Evenly_Separated_Label'])\n",
    "\n",
    "# Perform the chi-squared test\n",
    "chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "\n",
    "# Output the chi-squared statistic and p-value\n",
    "print(f\"Chi-Squared Statistic: {chi2}\")\n",
    "print(f\"P-Value: {p}\")\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Significance level\n",
    "if p <= alpha:\n",
    "    print(\"There is a significant association between the two categorical variables Stock_Value_Evenly_Separated and TextBlob_Evenly_Separated_Label.\")\n",
    "else:\n",
    "    print(\"There is no significant association between the two categorical variables Stock_Value_Evenly_Separated and TextBlob_Evenly_Separated_Label.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
