{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys  \n",
    "from selenium.webdriver.common.action_chains import ActionChains  \n",
    "\n",
    "import pyautogui  \n",
    "import pandas as pd\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datensammlung: Artikel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dax_companies = {\n",
    "    36714349 : \"Adidas\", #N\n",
    "    98641 : \"Airbus Group (EADS)\", #N\n",
    "    83219 : \"Allianz\", #N\n",
    "    34694526 : \"BASF\", #N\n",
    "    25272187 : \"Bayer\", #N\n",
    "    81500 : \"Beiersdorf\", #N\n",
    "    81490 : \"BMW\", #N\n",
    "    28975512 : \"Brenntag\", #N\n",
    "    83139 : \"Commerzbank\", #N\n",
    "    81967 : \"Continental\", #N\n",
    "    12587335 : \"Covestro\", #L\n",
    "    208894340 : \"Daimler Truck\", #L\n",
    "    81348 : \"Deutsche Bank\", #L\n",
    "    3459922 : \"Deutsche Börse\", #L\n",
    "    181029 : \"Deutsche Telekom\", #L\n",
    "    82088 : \"DHL Group (ex Deutsche Post)\", #L\n",
    "    21074892 : \"E.ON\", #L\n",
    "    82235 : \"Fresenius\", #L\n",
    "    182351 : \"Hannover Rück\", #L\n",
    "    82340 : \"Heidelberg Materials\", #L\n",
    "    82344 : \"Henkel\", #J\n",
    "    82561 : \"Infineon\", #J\n",
    "    82840 : \"Mercedes-Benz Group (Daimler)\", #J\n",
    "    82676 : \"Merck\", #J\n",
    "    12254991 : \"MTU Aero Engines\", #J\n",
    "    83258 : \"Münchener Rück\", #J\n",
    "    231291652 : \"Porsche AG (Vz.)\", #J\n",
    "    21178031 : \"Porsche Automobil Holding SE\", #J\n",
    "    90268 : \"Qiagen NV\", #J\n",
    "    82811 : \"Rheinmetall\", #J\n",
    "    82818 : \"RWE\",        # M\n",
    "    82849 : \"SAP\",        # M\n",
    "    82852 : \"Sartorius (Vz.)\",        # M\n",
    "    82902 : \"Siemens\",        # M\n",
    "    180455076 : \"Siemens Energy\",        # M\n",
    "    134397957 : \"Siemens Healthineers\",        # M\n",
    "    15630917 : \"Symrise\",        # M\n",
    "    83057 : \"Volkswagen (Vz.)\",        # M\n",
    "    62903083 : \"Vonovia\",        # M\n",
    "    81388537 : \"Zalando\"        # M\n",
    "          }\n",
    "\n",
    "\n",
    "news_subtypes = {\n",
    "    1 : \"Aktieneinstufung\",\n",
    "    2 : \"Analyse\",\n",
    "    3 : \"Directors Dealings\",\n",
    "    4 : \"Empfehlung\",\n",
    "    5 : \"Erklärstück\",\n",
    "    6 : \"Fundamentalanalyse\",\n",
    "    7 : \"Interview\",\n",
    "    8 : \"Kommentar\",\n",
    "    9 : \"Marktbericht\",\n",
    "    10 : \"News\", \n",
    "    11 : \"Pflichtmitteilung\",\n",
    "    12 : \"Pressemitteilung\",\n",
    "    13 : \"Ratgeber\",\n",
    "    14 : \"Technische Analyse\",\n",
    "    15 : \"Themen-Spezial\"\n",
    "}\n",
    "\n",
    "# Words that are marked as paragraphs in the HTML structure, but are not relevant for the analysis.\n",
    "filtered_words = [\"Top Aktien\", \"Top Märkte\", \"Ratgeber\", \"onvista media GmbH\", \"Rechtliche Hinweise\", \"App\", \"Social Media\", \"Veröffentlichung der Original-Studie\", \"Erstmalige Weitergabe der Original-Studie\"]  \n",
    "\n",
    "detailedFeedback = True  # True if the title, date, source, URL and content of each article are to be displayed as feedback in the terminal. If False, only general progress is displayed.\n",
    "zoom_out = True  # True if the browser is to be zoomed out to 80%.\n",
    "windows = True  # True if Windows device is used, False for Mac (regarding keyboard shortcuts to zoom out).\n",
    "\n",
    "driver = webdriver.Firefox()\n",
    "driver.set_window_size(1920, 1080)\n",
    "\n",
    "# Iteration over all keys of the companies from the dictionary 'dax_companies'.\n",
    "for key in dax_companies.keys():  \n",
    "    \n",
    "    article_data = []\n",
    "    \n",
    "    # Iteration per company across all 15 news types\n",
    "    for subtype in news_subtypes.keys():  \n",
    "        \n",
    "        # Iteration per company and subtype over max. 10 page numbers\n",
    "        for page in range(0,10):  \n",
    "            \n",
    "            driver.get(f'https://www.onvista.de/news/finder?page={page}&entityType=STOCK&entityValue={key}&idSubTypeGroups={subtype}')  # Filtered pages can be called up via the company-specific key\n",
    "            \n",
    "            time.sleep(random.uniform(4,5))\n",
    "\n",
    "            if zoom_out and windows:\n",
    "                pyautogui.keyDown('ctrl')  \n",
    "                pyautogui.press('-')\n",
    "                pyautogui.press('-')\n",
    "                pyautogui.keyUp('ctrl')\n",
    "                time.sleep(1)\n",
    "                zoom_out = False\n",
    "            else:\n",
    "                pyautogui.keyDown('command')  \n",
    "                pyautogui.press('-')\n",
    "                pyautogui.press('-')\n",
    "                pyautogui.keyUp('command')\n",
    "                time.sleep(1)\n",
    "                zoom_out = False\n",
    "\n",
    "            # Cookie Banner Handling\n",
    "            try:\n",
    "                iframe = driver.find_element(By.CSS_SELECTOR, \"#sp_message_container_800509 > iframe\")  # id of the div above the iframe containing the button on the cookie pop-up\n",
    "                driver.switch_to.frame(iframe)  # Switches the focus of the webdriver to the content of the iframe\n",
    "                \n",
    "                button = driver.find_element(By.XPATH, \"//button[@class='message-component message-button no-children focusable sp_choice_type_13']\").click()\n",
    "                driver.switch_to.default_content()    # Switches the focus of the web driver to the content of the web page\n",
    "\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "            \n",
    "            time.sleep(1)\n",
    "\n",
    "\n",
    "            # Article overview:\n",
    "            try:\n",
    "\n",
    "                \n",
    "                articles = driver.find_elements(By.XPATH,'//div[@class=\"ArticleTeaser_ov-article-teaser__content__yC6QF flex-layout__grow--1\"]')\n",
    "                counter = 0   #Counter to give feedback on the progress of the scraping.\n",
    "\n",
    "                if len(articles) == 0:  # Checks whether the current page of the article overview is empty.\n",
    "                    print(\"#\"*100)\n",
    "                    print(f\"[o] Auf Seite {page+1} wurden keine Artikel gefunden.\")\n",
    "                    print(\"#\"*100)\n",
    "\n",
    "                    break  # Interrupts the iteration over the page numbers\n",
    "\n",
    "                else:\n",
    "                    print(\"#\"*100)\n",
    "                    print(f\"[+] Es wurden {len(articles)} Artikel für {dax_companies[key]} zum Newstyp '{news_subtypes[subtype]}' auf Seite {page+1} gefunden.\")\n",
    "                    print(\"#\"*100)\n",
    "\n",
    "            except NoSuchElementException:                \n",
    "                pass\n",
    "\n",
    "            # Iteration over all articles found\n",
    "            for article in articles:\n",
    "                \n",
    "                article.location_once_scrolled_into_view  # Automatic scrolling to each article\n",
    "                time.sleep(random.uniform(1, 2.5))\n",
    "\n",
    "                try:\n",
    "                    ad_element = article.find_element(By.XPATH, \".//div[text()='Werbung']\")\n",
    "                    vid_element = article.find_element(By.XPATH, \".//div[text()='Videoanalyse']\")\n",
    "\n",
    "                    if ad_element or vid_element:\n",
    "                        print(\"-\"*100)\n",
    "                        print(f\"[*] Werbung gefunden\")\n",
    "                        print(\"-\"*100)\n",
    "                        counter += 1  # Since article is skipped, counter for next article must be adjusted\n",
    "                        continue      \n",
    "\n",
    "                except NoSuchElementException:\n",
    "                    pass\n",
    "                \n",
    "                \n",
    "                article_link =  article.find_element(By.XPATH,'.//strong[@class=\"ov-display--block ov-word-wrap\"]')\n",
    "                actions = ActionChains(driver)\n",
    "                \n",
    "                if windows:                   \n",
    "                    actions.key_down(Keys.CONTROL).click(article_link).key_up(Keys.CONTROL).perform()  # Opens article in a new tab\n",
    "                else: \n",
    "                    actions.key_down(Keys.COMMAND).click(article_link).key_up(Keys.COMMAND).perform()\n",
    "\n",
    "                driver.switch_to.window(driver.window_handles[1])  # Focus of the webdriver is directed to new tab\n",
    "\n",
    "                time.sleep(random.uniform(4.1, 6.4))  # Waiting time to ensure that page is fully loaded and to simulate natural user behaviour\n",
    "\n",
    "                # Extraction of the title\n",
    "                try:\n",
    "                    WebDriverWait(driver, 60).until(EC.presence_of_element_located((By.XPATH,'//h1[@class=\"headline headline--h1 headline--full-width outer-spacing--xxsmall-bottom\"]')))   \n",
    "                    title = driver.find_element(By.XPATH, '//h1[@class=\"headline headline--h1 headline--full-width outer-spacing--xxsmall-bottom\"]').text.strip() \n",
    "                    \n",
    "                except NoSuchElementException:\n",
    "                    title = \"NO_TITLE\"\n",
    "                \n",
    "                except TimeoutException: \n",
    "                    print(\"[*] Seite konnte innerhalb von 60 Sekunden nicht geladen werden! Fahre fort mit nächsten Artikel.\")\n",
    "                    driver.close()  \n",
    "                    driver.switch_to.window(driver.window_handles[0]) \n",
    "                    counter += 1\n",
    "                    continue\n",
    "\n",
    "                # Extraction of the date and time of publication\n",
    "                try:\n",
    "                    date = driver.find_element(By.XPATH, '//time[@class=\"color--cd-anthracite\"]').text.strip()\n",
    "                    \n",
    "                except NoSuchElementException:\n",
    "                    date = \"NO_DATE\"\n",
    "\n",
    "\n",
    "                # Extraction of the source\n",
    "                try:\n",
    "                    source = driver.find_element(By.XPATH, '//a[@class=\"link link--unstyled link--underline\"]').text.strip()\n",
    "                \n",
    "                except NoSuchElementException:\n",
    "                    source = \"NO_SOURCE\"\n",
    "\n",
    "                time.sleep(1)\n",
    "                # Extraction of the text content. Depending on the article structure, different approaches are needed to collect the content.\n",
    "                try:  \n",
    "                    \n",
    "                    if \"dpa\" in source and subtype == 3 or subtype == 12:  # dpa publishes \"Directors Dealing\" and \"Press Releases\" with pre-tag at subtype.\n",
    "                        pre = driver.find_element(By.TAG_NAME, \"pre\").text  # rarely occurring pre-tag\n",
    "                        if len(pre) > 100:                           \n",
    "                            text = pre\n",
    "\n",
    "                    elif \"EQS\" in source:  # Source that publishes public info in the form of tables\n",
    "\n",
    "                        text = driver.find_element(By.TAG_NAME, \"table\").text\n",
    "\n",
    "                    else :  # Remaining articles in paragraphs\n",
    "                            \n",
    "                        article_text = driver.find_elements(By.TAG_NAME,'p')  # Contains all paragraphs of the current article. The content of the article is best accessed via the paragraphs.\n",
    "                        time.sleep(1)\n",
    "\n",
    "                        # Since partially not recognisable, it is checked whether article_text is empty in order to try the following approaches\n",
    "                        if article_text is None:  \n",
    "\n",
    "                            article_text = driver.find_elements(By.CSS_SELECTOR, 'p.paragraph') \n",
    "\n",
    "                        elif article_text is None:\n",
    "\n",
    "                            article_text = driver.find_elements(By.XPATH, '//p[@class=\"paragraph Styles_ov-content-item-list__item__wK2EM\"]') \n",
    "\n",
    "                    \n",
    "                        text_list = []  # List that is to contain one paragraph per element and is later combined into a string (text) with line breaks per element.\n",
    "\n",
    "                        # Iteration over all contained paragraphs\n",
    "                        for paragraph in article_text: \n",
    "                            \n",
    "                            paragraph.location_once_scrolled_into_view\n",
    "                            tx = paragraph.text\n",
    "                            time.sleep(0.5)\n",
    "                            text_list.append(tx)  \n",
    "                            \n",
    "                            # The last 9 elements are mostly/always the words that occur in 'filtered_words', but which have been declared as paragraphs according to the HTML structure.\n",
    "                            for element in text_list[-9:]:  \n",
    "\n",
    "                                if element in filtered_words:\n",
    "                                    text_list.remove(element) \n",
    "\n",
    "                            text = '\\n'.join(text_list)  # The paragraphs are joined together to form a string, which is separated by line breaks (\\n).\n",
    "\n",
    "                except NoSuchElementException:\n",
    "                    text = \"NO_TEXT\"\n",
    "\n",
    "                except StaleElementReferenceException:\n",
    "                    print(\"[*] Stale Element Reference! Fahre fort mit nächsten Artikel.\")\n",
    "                    driver.close()  # Tab schließen\n",
    "                    driver.switch_to.window(driver.window_handles[0]) \n",
    "                    continue\n",
    "\n",
    "                # Merging the collected data of the article\n",
    "                data = {\"Unternehmen\" : dax_companies[key], \"Newstyp\" : news_subtypes[subtype],  \"Titel\" : title, \"Datum\" : date, \"Quelle\" : source, \"URL\" : driver.current_url, \"Text\" : text}  \n",
    "\n",
    "                article_data.append(data)\n",
    "                \n",
    "                counter += 1\n",
    "\n",
    "                print(\"-\"*100)\n",
    "                print(f\"[*] Artikel {counter} / {len(articles)} auf Seite {page+1} überprüft.\")\n",
    "                print(\"-\"*100)\n",
    "\n",
    "                if detailedFeedback:\n",
    "                    print(f\"Unternehmen: {dax_companies[key]}\")\n",
    "                    print(f\"Newstyp: {news_subtypes[subtype]}\")\n",
    "                    print(f\"Titel: {title}\")\n",
    "                    print(f\"Datum: {date}\")\n",
    "                    print(f\"Quelle: {source}\")\n",
    "                    print(f\"URL: {driver.current_url}\")\n",
    "                    print(f\"Inhalt:\\n{text}\")\n",
    "                    print(\"-\"*100)\n",
    "\n",
    "                driver.close()  # closing tab\n",
    "                driver.switch_to.window(driver.window_handles[0])  # Focus back to the first tab with the overview of the articles\n",
    "\n",
    "\n",
    "\n",
    "    company = dax_companies[key]\n",
    "\n",
    "    df = pd.DataFrame(article_data)\n",
    "\n",
    "    df.to_excel(f'data/Onvista_Articles-{company}.xlsx', index=False)\n",
    "    df.to_csv(f'data/Onvista_Articles-{company}.csv', index=False)\n",
    "\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
