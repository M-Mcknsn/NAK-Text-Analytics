{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys  \n",
    "from selenium.webdriver.common.action_chains import ActionChains  \n",
    "\n",
    "import pyautogui  \n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "#import re\n",
    "\n",
    "#  In Terminal oder Anaconda Prompt:\n",
    "#  pip install selenium, pyautogui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datensammlung: Artikel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dax_companies = {\n",
    "    36714349 : \"Adidas\", #N\n",
    "    98641 : \"Airbus Group (EADS)\", #N\n",
    "    83219 : \"Allianz\", #N\n",
    "    34694526 : \"BASF\", #N\n",
    "    25272187 : \"Bayer\", #N\n",
    "    81500 : \"Beiersdorf\", #N\n",
    "    81490 : \"BMW\", #N\n",
    "    28975512 : \"Brenntag\", #N\n",
    "    83139 : \"Commerzbank\", #N\n",
    "    81967 : \"Continental\", #N\n",
    "    12587335 : \"Covestro\", #L\n",
    "    208894340 : \"Daimler Truck\", #L\n",
    "    81348 : \"Deutsche Bank\", #L\n",
    "    3459922 : \"Deutsche Börse\", #L\n",
    "    181029 : \"Deutsche Telekom\", #L\n",
    "    82088 : \"DHL Group (ex Deutsche Post)\", #L\n",
    "    21074892 : \"E.ON\", #L\n",
    "    82235 : \"Fresenius\", #L\n",
    "    182351 : \"Hannover Rück\", #L\n",
    "    82340 : \"Heidelberg Materials\", #L\n",
    "    82344 : \"Henkel\", #J\n",
    "    82561 : \"Infineon\", #J\n",
    "    82840 : \"Mercedes-Benz Group (Daimler)\", #J\n",
    "    82676 : \"Merck\", #J\n",
    "    12254991 : \"MTU Aero Engines\", #J\n",
    "    83258 : \"Münchener Rück\", #J\n",
    "    231291652 : \"Porsche AG (Vz.)\", #J\n",
    "    21178031 : \"Porsche Automobil Holding SE\", #J\n",
    "    90268 : \"Qiagen NV\", #J\n",
    "    82811 : \"Rheinmetall\", #J\n",
    "    82818 : \"RWE\",        # M\n",
    "    82849 : \"SAP\",        # M\n",
    "    82852 : \"Sartorius (Vz.)\",        # M\n",
    "    82902 : \"Siemens\",        # M\n",
    "    180455076 : \"Siemens Energy\",        # M\n",
    "    134397957 : \"Siemens Healthineers\",        # M\n",
    "    15630917 : \"Symrise\",        # M\n",
    "    83057 : \"Volkswagen (Vz.)\",        # M\n",
    "    62903083 : \"Vonovia\",        # M\n",
    "    81388537 : \"Zalando\"        # M\n",
    "          }\n",
    "\n",
    "\n",
    "news_subtypes = {\n",
    "    1 : \"Aktieneinstufung\",\n",
    "    2 : \"Analyse\",\n",
    "    3 : \"Directors Dealings\",\n",
    "    4 : \"Empfehlung\",\n",
    "    5 : \"Erklärstück\",\n",
    "    6 : \"Fundamentalanalyse\",\n",
    "    7 : \"Interview\",\n",
    "    8 : \"Kommentar\",\n",
    "    9 : \"Marktbericht\",\n",
    "    10 : \"News\", \n",
    "    11 : \"Pflichtmitteilung\",\n",
    "    12 : \"Pressemitteilung\",\n",
    "    13 : \"Ratgeber\",\n",
    "    14 : \"Technische Analyse\",\n",
    "    15 : \"Themen-Spezial\"\n",
    "}\n",
    "\n",
    "\n",
    "filtered_words = [\"Top Aktien\", \"Top Märkte\", \"Ratgeber\", \"onvista media GmbH\", \"Rechtliche Hinweise\", \"App\", \"Social Media\", \"Veröffentlichung der Original-Studie\", \"Erstmalige Weitergabe der Original-Studie\"]  # Wörter die in der HTML Struktur als Paragraphen gekennzeichnet werden, aber nicht interessant für die Analyse sind\n",
    "\n",
    "detailedFeedback = True  # True wenn Titel, Datum, Quelle, URL und Inhalt jedes Artikel als feedback im Terminal angezeigt werden soll. Bei False wird nur genereller Fortschritt ausgegeben.\n",
    "zoom_out = True  # True wenn im Browser auf 80 % herausgezommt werden soll\n",
    "windows = True  # True wenn Windows Gerät genutzt wird, False für Mac (bzgl. Tastenkürzel zum herauszoomen)\n",
    "\n",
    "driver = webdriver.Firefox()\n",
    "#driver.maximize_window()\n",
    "driver.set_window_size(1920, 1080)\n",
    "\n",
    "# Iteration über alle keys der Unternehmen aus dem dictionary 'dax_companies'\n",
    "for key in dax_companies.keys():  \n",
    "    \n",
    "    article_data = []\n",
    "    \n",
    "    # Iteration je Unternehmen über alle 15 Newstypen\n",
    "    for subtype in news_subtypes.keys():  \n",
    "        \n",
    "        # Iteration je Unternehmen und Subtyp über max. 10 Seitenzahlen\n",
    "        for page in range(0,10):  \n",
    "            \n",
    "            driver.get(f'https://www.onvista.de/news/finder?page={page}&entityType=STOCK&entityValue={key}&idSubTypeGroups={subtype}')  # gefilterte Seiten lassen sich über den unternehmensspezifischen key aufrufen\n",
    "            time.sleep(random.uniform(4,5))\n",
    "\n",
    "            if zoom_out and windows:\n",
    "                pyautogui.keyDown('ctrl')  \n",
    "                pyautogui.press('-')\n",
    "                pyautogui.press('-')\n",
    "                pyautogui.keyUp('ctrl')\n",
    "                time.sleep(1)\n",
    "                zoom_out = False\n",
    "            else:\n",
    "                pyautogui.keyDown('command')  \n",
    "                pyautogui.press('-')\n",
    "                pyautogui.press('-')\n",
    "                pyautogui.keyUp('command')\n",
    "                time.sleep(1)\n",
    "                zoom_out = False\n",
    "\n",
    "            # Cookie Banner Handling\n",
    "            try:\n",
    "                iframe = driver.find_element(By.CSS_SELECTOR, \"#sp_message_container_800509 > iframe\")  # id des Divs über dem Iframe, das den Button auf des Cookie-Pop-up enthält\n",
    "                driver.switch_to.frame(iframe)  # Wechselt den Fokus des Webdrivers auf den Inhalt des iframes\n",
    "                \n",
    "                button = driver.find_element(By.XPATH, \"//button[@class='message-component message-button no-children focusable sp_choice_type_13']\").click()\n",
    "                driver.switch_to.default_content()    # Wechselt den Fokus des Webdrivers auf den Inhalt der Webseite\n",
    "\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "            \n",
    "           \n",
    "            # Artikelübersicht\n",
    "            try:\n",
    "\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH,'//div[@class=\"ArticleTeaser_ov-article-teaser__content__yC6QF flex-layout__grow--1\"]')))\n",
    "                articles = driver.find_elements(By.XPATH,'//div[@class=\"ArticleTeaser_ov-article-teaser__content__yC6QF flex-layout__grow--1\"]')\n",
    "                counter = 0  # Counter um feedback über Fortschritt des Scraping zu geben.\n",
    "\n",
    "                if len(articles) == 0:  #Überprüft ob aktuelle Seite der Artikelübersicht leer ist.\n",
    "                    print(\"#\"*100)\n",
    "                    print(f\"[o] Auf Seite {page+1} wurden keine Artikel gefunden.\")\n",
    "                    print(\"#\"*100)\n",
    "\n",
    "                    break  # Unterbricht die Iteration über die Seitenzahl\n",
    "\n",
    "                else:\n",
    "                    print(\"#\"*100)\n",
    "                    print(f\"[+] Es wurden {len(articles)} Artikel für {dax_companies[key]} zum Newstyp '{news_subtypes[subtype]}' auf Seite {page+1} gefunden.\")\n",
    "                    print(\"#\"*100)\n",
    "\n",
    "            except NoSuchElementException:                \n",
    "                pass\n",
    "\n",
    "            except TimeoutException: \n",
    "                print(\"[*] Seite konnte innerhalb von 10 Sekunden nicht geladen werden!\")\n",
    "                pass\n",
    "\n",
    "\n",
    "            # Iteration über alle gefundenen Artikel\n",
    "            for article in articles:\n",
    "                \n",
    "                article.location_once_scrolled_into_view  # Automatisches Scrollen zu jedem Artikel\n",
    "                time.sleep(random.uniform(1, 2.5))\n",
    "\n",
    "                try:\n",
    "                    ad_element = article.find_element(By.XPATH, \".//div[text()='Werbung']\")\n",
    "                    #ad_element_text = ad_element.split('\\n')[0]\n",
    "\n",
    "                    if ad_element:\n",
    "                        print(\"-\"*100)\n",
    "                        print(f\"[*] Werbung gefunden\")\n",
    "                        print(\"-\"*100)\n",
    "                        counter += 1  # Da Artikel übersprungen wird, muss counter für den nächsten Artikel angepasst werden\n",
    "                        continue      \n",
    "                    # if \"Werbung\" in ad_element_text:  # Wenn Werbung im Artikel Element enthalten ist, soll das nächste Element betrachtet werden\n",
    "                    #     print(\"-\"*100)\n",
    "                    #     print(f\"[*] Werbung gefunden\")\n",
    "                    #     print(\"-\"*100)\n",
    "                    #     counter += 1  # Da Artikel übersprungen wird, muss counter für den nächsten Artikel angepasst werden\n",
    "                    #     continue            \n",
    "                except NoSuchElementException:\n",
    "                    pass\n",
    "                \n",
    "                \n",
    "                article_link =  article.find_element(By.XPATH,'.//strong[@class=\"ov-display--block ov-word-wrap\"]')\n",
    "                actions = ActionChains(driver)\n",
    "                \n",
    "                if windows:                   \n",
    "                    actions.key_down(Keys.CONTROL).click(article_link).key_up(Keys.CONTROL).perform()  # Öffnet Artikel in einem neuen Tab\n",
    "                else: \n",
    "                    actions.key_down(Keys.COMMAND).click(article_link).key_up(Keys.COMMAND).perform()\n",
    "\n",
    "                driver.switch_to.window(driver.window_handles[1])  # Fokus des Webdrivers wird auf neuen Tab gerichtet\n",
    "\n",
    "                time.sleep(random.uniform(4.1, 6.4))  # Wartezeit um sicher zu gehen, dass Seite vollständig geladen wurde sowie um natürliches Nutzerverhalten zu simulieren\n",
    "\n",
    "\n",
    "                # # Umgang mit Werbung, ggf. überflüssig\n",
    "                # try:\n",
    "                #     ad = driver.find_element(By.XPATH, '//div[@class=\"flex-layout flex-layout__align-items--center flex-layout__justify-content--end text-size--xsmall ov-subline\"]').text.strip()  # Extraktion dem Titel aus der HTML-Struktur, teweilweise problematisch zu erkennen\n",
    "                #     ad_text = ad.split('\\n')\n",
    "\n",
    "                #     print(ad_text[0])\n",
    "\n",
    "                #     if \"Werbung\" in ad_text[0]:  # Umgang mit Werbung die direkt auf onvista.de dargestellt wird\n",
    "                #         driver.close()\n",
    "                #         driver.switch_to.window(driver.window_handles[0])  # Fokus zurück zum ersten Tab\n",
    "                        \n",
    "                #         continue\n",
    "\n",
    "                #     current_url = driver.current_url\n",
    "                #     if \"onvista.de\" not in current_url:  # Umgang mit Werbung die über ein Element aus der Artikelübersicht zu einer Webseite außerhalb von onvista führt\n",
    "                #         driver.close()\n",
    "                #         driver.switch_to.window(driver.window_handles[0])\n",
    "                #         continue\n",
    "\n",
    "                #except NoSuchElementException:\n",
    "                #    pass\n",
    "                \n",
    "                \n",
    "                # Extraktion des Titels\n",
    "                try:\n",
    "                    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH,'//h1[@class=\"headline headline--h1 headline--full-width outer-spacing--xxsmall-bottom\"]')))   \n",
    "                    title = driver.find_element(By.XPATH, '//h1[@class=\"headline headline--h1 headline--full-width outer-spacing--xxsmall-bottom\"]').text.strip() \n",
    "                    \n",
    "                except NoSuchElementException:\n",
    "                    title = \"NO_TITLE\"\n",
    "\n",
    "                except TimeoutException: \n",
    "                    print(\"[*] Seite konnte innerhalb von 10 Sekunden nicht geladen werden!\")\n",
    "                    continue\n",
    "\n",
    "                # Extraktion des Datums und Uhrzeit der Veröffentlichung\n",
    "                try:\n",
    "                    date = driver.find_element(By.XPATH, '//time[@class=\"color--cd-anthracite\"]').text.strip()\n",
    "                    \n",
    "\n",
    "                except NoSuchElementException:\n",
    "                    date = \"NO_DATE\"\n",
    "\n",
    "\n",
    "                # Extraktion der Quelle\n",
    "                try:\n",
    "                    source = driver.find_element(By.XPATH, '//a[@class=\"link link--unstyled link--underline\"]').text.strip()\n",
    "                    \n",
    "                \n",
    "                except NoSuchElementException:\n",
    "                    source = \"NO_SOURCE\"\n",
    "\n",
    "\n",
    "                # Extrakktion der Text-Inhalte. Je nach Artikelstruktur werden verschiedene Ansätze zur Sammlung der Inhalte benötigt, geht durchaus eleganter:\n",
    "                try:  \n",
    "                    \n",
    "                    if \"dpa\" in source and subtype == 3 or subtype == 12:  # dpa veröffentlich bei subtype \"Directors Dealing\" und \"Pressemitteilungen\" mit pre tag\n",
    "                        pre = driver.find_element(By.TAG_NAME, \"pre\").text  # selten vorkommendes pre tag\n",
    "                        if len(pre) > 100:                           \n",
    "                            text = pre\n",
    "\n",
    "                    elif \"EQS\" in source:  # Quelle die öffentliche Bekanntgaben in Form von Tabellen veröffentlicht \n",
    "\n",
    "                        text = driver.find_element(By.TAG_NAME, \"table\").text\n",
    "\n",
    "                        #text = tables[0].text\n",
    "\n",
    "                    else :  # Restliche Artikel in Paragraphen\n",
    "                            \n",
    "                        article_text = driver.find_elements(By.TAG_NAME,'p') # Enthält alle Paragraphen des aktuellen Artikels. Inhalt des Artikel ist am besten über die Paragraphen ansteuerbar.\n",
    "                        time.sleep(random.uniform(1.2, 2))\n",
    "\n",
    "                        if article_text is None:  # Da teilweise nicht erkennbar, wird überprüft ob article_text leer ist, um die folgenden Ansätze zu versuchen\n",
    "\n",
    "                            article_text = driver.find_elements(By.CSS_SELECTOR, 'p.paragraph') #or  driver.find_elements(By.XPATH, '//p[@class=\"paragraph Styles_ov-content-item-list__item__wK2EM\"]') \n",
    "\n",
    "                        elif article_text is None:\n",
    "\n",
    "                            article_text = driver.find_elements(By.XPATH, '//p[@class=\"paragraph Styles_ov-content-item-list__item__wK2EM\"]') \n",
    "\n",
    "                    \n",
    "                        text_list = []  # Liste, die je Element einen Paragraphen enthalten soll und später mit Zeilenumbrüche je Element zu einem String (text) zusammegefügt wird\n",
    "\n",
    "                        for paragraph in article_text:  # Iteration über alle enthaltenen Paragraphen\n",
    "                            \n",
    "                            paragraph.location_once_scrolled_into_view\n",
    "                            time.sleep(0.5)\n",
    "                            text_list.append(paragraph.text)  \n",
    "                            \n",
    "                            for element in text_list[-9:]:  # Die letzten 9 Elemente sind meist/immer die in 'filtered_words' vorkommende Wörter, welche laut HTML-Struktur jedoch als paragraph deklariert wurden.\n",
    "\n",
    "                                if element in filtered_words:\n",
    "                                    text_list.remove(element) \n",
    "\n",
    "                            text = '\\n'.join(text_list)  # Aneinanderfügung der Paragraphen zu einem String, welcher durch Zeilenumbrüche (\\n) getrennet wird.\n",
    "\n",
    "                except NoSuchElementException:\n",
    "                    text = \"NO_TEXT\"\n",
    "\n",
    "                url = driver.current_url\n",
    "\n",
    "                data = {\"Unternehmen\" : dax_companies[key], \"Newstyp\" : news_subtypes[subtype],  \"Titel\" : title, \"Datum\" : date, \"Quelle\" : source, \"URL\" : url, \"Text\" : text}  # Zusammenführung der gesammelten Daten des Artikels\n",
    "\n",
    "                article_data.append(data)\n",
    "                \n",
    "                counter += 1\n",
    "\n",
    "                print(\"-\"*100)\n",
    "                print(f\"[*] Artikel {counter} / {len(articles)} auf Seite {page+1} überprüft.\")\n",
    "                print(\"-\"*100)\n",
    "\n",
    "                if detailedFeedback:\n",
    "                    print(f\"Unternehmen: {dax_companies[key]}\")\n",
    "                    print(f\"Newstyp: {news_subtypes[subtype]}\")\n",
    "                    print(f\"Titel: {title}\")\n",
    "                    print(f\"Datum: {date}\")\n",
    "                    print(f\"Quelle: {source}\")\n",
    "                    print(f\"URL: {url}\")\n",
    "                    print(f\"Inhalt:\\n{text}\")\n",
    "                    print(\"-\"*100)\n",
    "\n",
    "                driver.close()  # Tab schließen\n",
    "                driver.switch_to.window(driver.window_handles[0])  # Fokus zurück zum ersten Tab mit der Übersicht der Artikel\n",
    "\n",
    "\n",
    "    # Zum Anfügen des aktuellen Datum/Uhrzeit + Unternehmensnamen an Dateinamen\n",
    "    now = datetime.datetime.now()  \n",
    "    date_time_str = now.strftime('%Y%m%d_%H%M%S')\n",
    "    company = dax_companies[key]\n",
    "\n",
    "    df = pd.DataFrame(article_data)\n",
    "\n",
    "    df.to_excel(f'data/Onvista_Articles-{company}.xlsx', index=False)\n",
    "    df.to_csv(f'data/Onvista_Articles-{company}.csv', index=False)\n",
    "\n",
    "driver.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
