{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Correlation Analysis\n",
    "*by XY, 2023*\n",
    "*Master \"Applied Data Science\" @ Nordakademie*\n",
    "*Modul: Text Analytics*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### General pre-work"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# Overall needed\n",
    "import pandas as pd # to work with data frames\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Needed for visualisations and smaller functions such as time tracking or saving files\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os # to define a dedicated output folder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "output_folder = 'data/analysis' # refer to a new folder to store only sentiment result files\n",
    "\n",
    "# check if folder can be found, else create it\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Add the normal distribution stock values to the combined sentiment table\n",
    "\n",
    "csv_file_path_normal_3 = 'data/transfer/cleaned_articles_normalverteilt_3.csv' # define the path of the input csv file with 3 categories, normal distribution\n",
    "\n",
    "# Load the data set\n",
    "df_3categories_normal = pd.read_csv(csv_file_path_normal_3, encoding='utf-8', quoting=csv.QUOTE_ALL) # ensuring the right encoding as in the csv file we still encounter incorrectly encoded special characters\n",
    "\n",
    "csv_file_path_combined_sentiments = 'data/sentiment_results/sentiment_results_combined.csv' # define the path of the input csv file with the sentiment results\n",
    "\n",
    "# Load the data set\n",
    "df_combined_sentiments = pd.read_csv(csv_file_path_combined_sentiments, encoding='utf-8', quoting=csv.QUOTE_ALL) # ensuring the right encoding as in the csv file we still encounter incorrectly encoded special characters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-Processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Row_Number                   Unternehmen Newstyp   Quelle Nearest_Date  \\\n",
      "0           1  Porsche Automobil Holding SE    News  onvista   2021-06-01   \n",
      "1           2                    Beiersdorf    News  onvista   2021-06-02   \n",
      "2           3          Heidelberg Materials    News  onvista   2021-06-02   \n",
      "\n",
      "                                        Cleaned_Text Stock_Value  \\\n",
      "0  neu Rumor Porschebörsengang Sixt Berenberg stu...     neutral   \n",
      "1  Beiersdorf Aktie Kaufempfehlung beflügeln Bere...    positive   \n",
      "2  Heidelbergcement klimaneutral Zementwerk Weg B...    positive   \n",
      "\n",
      "   TextBlob_Sentiment_Score TextBlob_Evenly_Separated_Label  \\\n",
      "0                   -0.0500                        Negative   \n",
      "1                    0.2000                        Positive   \n",
      "2                   -0.0875                        Negative   \n",
      "\n",
      "  TextBlob_Normal_Distribution_Label  NLTK_Sentiment  \\\n",
      "0                            Neutral         -0.3612   \n",
      "1                           Positive          0.0000   \n",
      "2                            Neutral         -0.4588   \n",
      "\n",
      "  NLTK_Evenly_Separated_Label NLTK_Normal_Distribution_Label Stock_ValueStd  \n",
      "0                    Negative                        Neutral        neutral  \n",
      "1                     Neutral                        Neutral       positive  \n",
      "2                    Negative                        Neutral        neutral  \n"
     ]
    }
   ],
   "source": [
    "# Merge the two data frames based on a common column, such as an index or a specific column name\n",
    "# In this example, I assume you want to use the index as the merge key\n",
    "df_merged_3_categories = df_combined_sentiments.merge(df_3categories_normal[['Stock_ValueStd']], left_index=True, right_index=True)\n",
    "\n",
    "# Save the merged data frame to a new variable or file if needed\n",
    "# merged_df contains the combined data with the \"Stock_ValueStd\" column added\n",
    "\n",
    "# If you want to save the merged data frame to a new CSV file, you can use the following:\n",
    "# merged_df.to_csv('merged_data.csv', index=False)\n",
    "\n",
    "print(df_merged_3_categories.head(3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#Rename and reposition columns\n",
    "\n",
    "# 1. Rename column \"Stock_Value\" to \"Stock_Value_evenly_separated\"\n",
    "df_merged_3_categories.rename(columns={'Stock_Value': 'Stock_Value_Evenly_Separated'}, inplace=True)\n",
    "\n",
    "# 2. Rename column \"Stock_ValueStd\" to \"Stock_Value_normal_distribution\"\n",
    "df_merged_3_categories.rename(columns={'Stock_ValueStd': 'Stock_Value_Normal_Distribution'}, inplace=True)\n",
    "\n",
    "# 3. Reorder columns to move \"Stock_Value_normal_distribution\" to the 8th column\n",
    "cols = df_merged_3_categories.columns.tolist()\n",
    "cols.insert(7, cols.pop(cols.index('Stock_Value_Normal_Distribution')))\n",
    "df_merged_3_categories = df_merged_3_categories[cols]\n",
    "\n",
    "# 4. Capitalize the stock value\n",
    "df_merged_3_categories['Stock_Value_Evenly_Separated'] = df_merged_3_categories['Stock_Value_Evenly_Separated'].str.capitalize()\n",
    "df_merged_3_categories['Stock_Value_Normal_Distribution'] = df_merged_3_categories['Stock_Value_Normal_Distribution'].str.capitalize()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the merged file in the correct repository folder\n",
    "\n",
    "# Save to an Excel file\n",
    "excel_output_file_analysis_3 = os.path.join(output_folder, 'analysis_3_categories.xlsx')\n",
    "df_merged_3_categories.to_excel(excel_output_file_analysis_3, index=False)\n",
    "\n",
    "# Save the results to a csv file with the same name\n",
    "csv_output_file_analysis_3 = os.path.join(output_folder, 'analysis_3_categories.csv')\n",
    "df_merged_3_categories.to_csv(csv_output_file_analysis_3, index=False, encoding='utf-8', quoting=csv.QUOTE_ALL)\n",
    "\n",
    "# Print final info\n",
    "print(f\"Results saved as {csv_output_file_analysis_3} and {excel_output_file_analysis_3}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Correlation Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3 Categories"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### TextBlob Even Separation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(df_merged_3_categories['Stock_Value_Evenly_Separated'], df_merged_3_categories['TextBlob_Evenly_Separated_Label'])\n",
    "\n",
    "# Perform the chi-squared test\n",
    "chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "\n",
    "# Output the chi-squared statistic and p-value\n",
    "print(f\"Chi-Squared Statistic: {chi2}\")\n",
    "print(f\"P-Value: {p}\")\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Significance level\n",
    "if p <= alpha:\n",
    "    print(\"There is a significant association between the two categorical variables Stock_Value_Evenly_Separated and TextBlob_Evenly_Separated_Label.\")\n",
    "else:\n",
    "    print(\"There is no significant association between the two categorical variables Stock_Value_Evenly_Separated and TextBlob_Evenly_Separated_Label.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Cramer's V (or Cramer's Phi) and the Phi Coefficient (φ), analysing strength of relationship"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate Cramer's V\n",
    "n = contingency_table.sum().sum()\n",
    "min_dim = min(contingency_table.shape) - 1\n",
    "cramer_v = (chi2 / n) ** 0.5 / min_dim\n",
    "\n",
    "# Calculate the Phi Coefficient (φ)\n",
    "phi_coefficient = (chi2 / n) ** 0.5\n",
    "\n",
    "print(f\"Cramer's V: {cramer_v}\")\n",
    "print(f\"Phi Coefficient (φ): {phi_coefficient}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Additional info about results\n",
    "*Modul: Text Analytics*\n",
    "\n",
    "Yes, it is **possible for Cramer's V (or Cramer's Phi) and the Phi Coefficient (φ) to be close to 0 while the chi-square test identifies a significant relationship**. This can occur when there is a statistically significant association between the variables, but the strength of that association is weak.\n",
    "\n",
    "The chi-square test primarily assesses the statistical significance of the association, meaning it tells you whether there is evidence that the two categorical variables are related. However, it doesn't provide information about the strength or the practical significance of that relationship.\n",
    "\n",
    "Cramer's V and the Phi Coefficient provide measures of effect size, indicating how strong the relationship is. A small effect size, reflected in values close to 0, suggests a weak association, while a large effect size indicates a strong association.\n",
    "\n",
    "So, it's possible for the chi-square test to detect a statistically significant relationship even if the association is weak, leading to low values for Cramer's V and Phi Coefficient. The significance test assesses whether there is any association, while the effect size measures how substantial that association is in practical terms."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the order for the categories\n",
    "order = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Create bar charts for each categorical variable with the specified order\n",
    "sns.countplot(data=df_merged_3_categories, x='Stock_Value_Evenly_Separated', order=order)\n",
    "plt.title('Distribution of Stock Value Categories')\n",
    "plt.show()\n",
    "\n",
    "sns.countplot(data=df_merged_3_categories, x='TextBlob_Evenly_Separated_Label', order=order)\n",
    "plt.title('Distribution of TextBlob Sentiment Label Categories')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "contingency_table = pd.crosstab(df_merged_3_categories['Stock_Value_Evenly_Separated'], df_merged_3_categories['TextBlob_Evenly_Separated_Label'])\n",
    "\n",
    "contingency_table.plot(kind='bar', stacked=True)\n",
    "plt.title('Stacked Bar Chart of Stock Value Categories vs. TextBlob Sentiment Label Categories')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "contingency_table.plot(kind='bar')\n",
    "plt.title('Clustered Bar Chart of Stock Value Categories vs. TextBlob Sentiment Label Categories')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a contingency table to count the co-occurrence of values\n",
    "contingency_table = pd.crosstab(df_merged_3_categories['Stock_Value_Evenly_Separated'], df_merged_3_categories['TextBlob_Evenly_Separated_Label'])\n",
    "\n",
    "# Define the order of categories\n",
    "category_order = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = contingency_table[category_order].plot(kind='bar', stacked=True, figsize=(8, 6,))\n",
    "\n",
    "# Add labels and a legend\n",
    "ax.set_xlabel('Stock Value')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Relationship Between Stock Value and TextBlob Sentiment Label')\n",
    "ax.legend(title='Sentiment Label', title_fontsize=12)\n",
    "\n",
    "plt.xticks(rotation=0)  # Keep x-axis labels horizontal\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a DataFrame to store the counts\n",
    "counts_df = pd.DataFrame(index=['Negative', 'Neutral', 'Positive'], columns=['Stock_Value_Evenly_Separated', 'TextBlob_Evenly_Separated_Label'])\n",
    "\n",
    "# Count how often each category appears for \"Stock_Value_Evenly_Separated\"\n",
    "counts_df['Stock_Value_Evenly_Separated'] = df_merged_3_categories['Stock_Value_Evenly_Separated'].value_counts()\n",
    "\n",
    "# Count how often both \"Stock_Value_Evenly_Separated\" and \"TextBlob_Evenly_Separated_Label\" are the same\n",
    "for category in ['Negative', 'Neutral', 'Positive']:\n",
    "    counts_df.loc[category, 'TextBlob_Evenly_Separated_Label'] = ((df_merged_3_categories['Stock_Value_Evenly_Separated'] == category) & (df_merged_3_categories['TextBlob_Evenly_Separated_Label'] == category)).sum()\n",
    "\n",
    "# Print the counts\n",
    "print(counts_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
