{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Sentiment Analysis\n",
    "*Jannik Labs, 2023*\n",
    "*Master \"Applied Data Science\" @ Nordakademie*\n",
    "*Modul: Text Analytics*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Intro\n",
    "\n",
    "Different approaches/methods or respective libraries possible for mapping sentiment values to the \"cleaned_articles_v1.csv\". Each coming in with its own characteristics, weaknesses and strengths:\n",
    "\n",
    "1. **TextBlob**\n",
    "- beginner-friendly and relatively easy to set up\n",
    "- pre-trained models for sentiment analysis\n",
    "- suitable for basic sentiment analysis tasks\n",
    "- limited customization options\n",
    "\n",
    "2. **NLTK Toolkit** - in general\n",
    "- wide range of tools for text processing, including sentiment analysis\n",
    "- more flexibility for creating custom sentiment analysis models\n",
    "\n",
    "    - **VADER**-- (**V**alence **A**ware **D**ictionary and s**E**ntiment **R**easoner) (PART OF NLTK)\n",
    "    - specific for Social Media, especially for informal texts like tweets and social media posts\n",
    "    - lexicon-based and comes with a pre-trained sentiment lexicon\n",
    "    - good for real-time sentiment analysis\n",
    "\n",
    "3. **Scikit-learn**\n",
    "- can be used to build a custom sentiment analysis model using machine learning\n",
    "- allows engineering of custom features for sentiment analysis\n",
    "\n",
    "4. **Transformer Models like BERT or GPT**\n",
    "- State-of-the-Art Models: Utilizes pre-trained transformer-based models (e.g., BERT, GPT) for sentiment analysis\n",
    "- High Performance: Provides state-of-the-art performance in NLP tasks\n",
    "- requires significant computational resources and large amounts of data\n",
    "\n",
    "### Decision\n",
    "For our use case custom sentiment models with special features are rather out of scope. Neither do we mainly analyse really short texts as found on Social Media (tweets on X etc.). Therefore, in order to ensure comparisons of different tools/libraries, here we will use:\n",
    "\n",
    "- TextBlob\n",
    "- NLTK Toolkit (using VADER) (still used for a comparison)\n",
    "- BERT (later specified)\n",
    "\n",
    "As ressource heaviness increases these tools will be used in this exact order."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentiment Analyses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### General pre-work"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# Overall needed\n",
    "import pandas as pd # to work with data frames\n",
    "import numpy as np\n",
    "\n",
    "# Needed for sentiment analyses and different approaches\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Needed for visualisations and smaller functions such as time tracking or saving files\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "import os # to define a dedicated output folder\n",
    "import time # to track the run time for different approaches"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_folder = 'data/sentiment_results' # refer to a new folder to store only sentiment result files\n",
    "\n",
    "# check if folder can be found, else create it\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Load the CSV file from the data cleaning part\n",
    "\n",
    "csv_file_path_even_3 = 'data/transfer/cleaned_articles_gleichverteilt_3.csv' # define the path of the input csv file with 3 categories\n",
    "csv_file_path_even_3 = 'data/transfer/cleaned_articles_gleichverteilt_3.csv' # define the path of the input csv file with 3 categories\n",
    "\n",
    "# Load the data sets, with the option of defining only a subset of the data (first x rows as an example). This way we can test ALL our approaches first and see some first results. Just use parameter \"nrows=x\". Total row number of the input is around 23.500.\n",
    "df_3categories = pd.read_csv(csv_file_path_even_3, encoding='utf-8', quoting=csv.QUOTE_ALL) # ensuring the right encoding as in the csv file we still encounter incorrectly encoded special characters\n",
    "df_5categories = pd.read_csv(csv_file_path_even_5, encoding='utf-8', quoting=csv.QUOTE_ALL)\n",
    "\n",
    "total_rows = len(df_3categories) # define total rows, used for progress prints in the analysis methods\n",
    "\n",
    "# Add a new column 'Row_Number' with the row number as the merge key for later\n",
    "df_3categories.insert(0, 'Row_Number', range(1, len(df_3categories) + 1))\n",
    "\n",
    "# Create separate data frame copies for the sentiment analysis approaches\n",
    "df_textblob_3 = df_3categories.copy()             # For TextBlob approach\n",
    "df_nltk_3 = df_3categories.copy()                 # For NLTK approach\n",
    "\n",
    "# Print the DataFrame with the row number as the first column\n",
    "print(df_3categories.head(n=5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TextBlob"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "used_approach = \"TextBlob\"  # Setting it for later reference\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize an empty list to store sentiment scores\n",
    "sentiment_scores = []\n",
    "\n",
    "# Initialize a counter for tracking progress\n",
    "current_row = 0\n",
    "\n",
    "# Loop through each row in the DataFrame\n",
    "for i, text in enumerate(df_textblob_3['Cleaned_Text']):\n",
    "    current_row += 1\n",
    "    print(f\"Analyzing text number {current_row} out of {len(df_textblob_3)} rows in the input file.\")\n",
    "\n",
    "    # Calculate TextBlob sentiment score\n",
    "    sentiment_score = TextBlob(text).sentiment.polarity\n",
    "\n",
    "    # Append sentiment score to the list\n",
    "    sentiment_scores.append(sentiment_score)\n",
    "\n",
    "# Add the calculated sentiment scores to the DataFrame\n",
    "df_textblob_3['TextBlob_Sentiment_Score'] = sentiment_scores\n",
    "\n",
    "# Calculate the elapsed time\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Calculate the mean and standard deviation of sentiment scores\n",
    "mean_score = df_textblob_3['TextBlob_Sentiment_Score'].mean()\n",
    "std_deviation = df_textblob_3['TextBlob_Sentiment_Score'].std()\n",
    "\n",
    "# Calculate the lower and upper thresholds for labeling based on a normal distribution\n",
    "lower_threshold = mean_score - std_deviation\n",
    "upper_threshold = mean_score + std_deviation\n",
    "\n",
    "# Function to categorize sentiment labels based on distribution\n",
    "def categorize_sentiment(score):\n",
    "    if score <= lower_threshold:\n",
    "        return 'Negative'\n",
    "    elif lower_threshold < score <= upper_threshold:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'\n",
    "\n",
    "# Apply the first labeling method: evenly separated\n",
    "df_textblob_3['TextBlob_Evenly_Separated_Label'] = pd.qcut(df_textblob_3['TextBlob_Sentiment_Score'], q=3, labels=['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "# Apply the second labeling method: based on normal distribution\n",
    "df_textblob_3['TextBlob_Normal_Distribution_Label'] = df_textblob_3['TextBlob_Sentiment_Score'].apply(categorize_sentiment)\n",
    "\n",
    "print(\"-\" * 100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate hours, minutes, and seconds from the elapsed time\n",
    "hours = int(elapsed_time // 3600)\n",
    "minutes = int((elapsed_time % 3600) // 60)\n",
    "seconds = int(elapsed_time % 60)\n",
    "\n",
    "# Format the elapsed time string\n",
    "elapsed_time_str = f\"{hours} hours, {minutes} mins, and {seconds} secs\"\n",
    "\n",
    "# End information about the run\n",
    "print(f\"The used approach was {used_approach}.\")\n",
    "print(f\"Elapsed time: {elapsed_time_str}.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the output in two file formats in dedicated files for only this current approach in the correct repository folder\n",
    "\n",
    "# Save the results to an Excel file\n",
    "excel_output_file_textblob = os.path.join(output_folder, 'sentiment_results_textblob.xlsx')\n",
    "df_textblob_3.to_excel(excel_output_file_textblob, index=False)\n",
    "\n",
    "# Save the results to a csv file with the same name\n",
    "csv_output_file_textblob = os.path.join(output_folder, 'sentiment_results_textblob.csv')\n",
    "df_textblob_3.to_csv(csv_output_file_textblob, index=False, encoding='utf-8', quoting=csv.QUOTE_ALL)\n",
    "\n",
    "# Print final info\n",
    "print(f\"Results saved as {csv_output_file_textblob} and {excel_output_file_textblob}.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Explorative Analysis of TextBlob"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the distribution of sentiment scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_textblob_3['TextBlob_Sentiment_Score'], bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Sentiment Scores (TextBlob)')\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the order of sentiment labels\n",
    "sentiment_order = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Create a countplot with a single color for all bars for Evenly Separated Logic\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.countplot(data=df_textblob_3, x='TextBlob_Evenly_Separated_Label', color='blue', order=sentiment_order)\n",
    "plt.xlabel('TextBlob Sentiment Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of TextBlob Sentiment Labels (Evenly Separated Logic)')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "\n",
    "# Add the actual frequency values on top of the bars without decimal values\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='bottom', fontsize=12, color='black')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Create a countplot with a single color for all bars for Normal Distribution Logic\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.countplot(data=df_textblob_3, x='TextBlob_Normal_Distribution_Label', color='orange', order=sentiment_order)\n",
    "plt.xlabel('TextBlob Sentiment Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of TextBlob Sentiment Labels (Normal Distribution Logic)')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "\n",
    "# Add the actual frequency values on top of the bars without decimal values\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='bottom', fontsize=12, color='black')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### NLTK (VADER)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "used_approach = \"NLTK_VADER\" #setting it for later reference\n",
    "\n",
    "# Initialize the SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Apply sentiment analysis and store the compound score in a new column\n",
    "df_nltk_3['NLTK_Sentiment'] = df_nltk_3['Cleaned_Text'].apply(lambda text: sia.polarity_scores(text)['compound'])\n",
    "\n",
    "for i, row in enumerate(df_nltk_3.index):\n",
    "    text = df_nltk_3.at[row, 'Cleaned_Text']\n",
    "    sentiment_score = sia.polarity_scores(text)['compound']\n",
    "    df_nltk_3.at[row, 'NLTK_Sentiment'] = sentiment_score\n",
    "\n",
    "    # Print progress message\n",
    "    print(f\"Text number {i + 1} out of all {total_rows} rows in the input file: Sentiment score = {sentiment_score}.\")\n",
    "\n",
    "# Calculate the elapsed time\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Define custom thresholds\n",
    "negative_threshold = -0.33\n",
    "positive_threshold = 0.33\n",
    "\n",
    "# Function to categorize sentiment labels based on custom thresholds\n",
    "def categorize_sentiment(score):\n",
    "    if score <= negative_threshold:\n",
    "        return 'Negative'\n",
    "    elif score <= positive_threshold:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'\n",
    "\n",
    "# Apply custom labeling method\n",
    "df_nltk_3['NLTK_Evenly_Separated_Label'] = df_nltk_3['NLTK_Sentiment'].apply(categorize_sentiment)\n",
    "\n",
    "# Rest of your code for calculating normal distribution labels\n",
    "mean_score = df_nltk_3['NLTK_Sentiment'].mean()\n",
    "std_deviation = df_nltk_3['NLTK_Sentiment'].std()\n",
    "\n",
    "# Calculate the lower and upper thresholds for labeling based on a normal distribution\n",
    "lower_threshold = mean_score - std_deviation\n",
    "upper_threshold = mean_score + std_deviation\n",
    "\n",
    "# Function to categorize sentiment labels based on distribution\n",
    "def categorize_sentiment(score):\n",
    "    if score <= lower_threshold:\n",
    "        return 'Negative'\n",
    "    elif score <= upper_threshold:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'\n",
    "\n",
    "# Apply the second labeling method: based on normal distribution\n",
    "df_nltk_3['NLTK_Normal_Distribution_Label'] = df_nltk_3['NLTK_Sentiment'].apply(categorize_sentiment)\n",
    "\n",
    "print(\"-\"*100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate hours, minutes, and seconds from the elapsed time\n",
    "hours = int(elapsed_time // 3600)\n",
    "minutes = int((elapsed_time % 3600) // 60)\n",
    "seconds = int(elapsed_time % 60)\n",
    "\n",
    "# Format the elapsed time string\n",
    "elapsed_time_str = f\"{hours} hours, {minutes} mins, and {seconds} secs\"\n",
    "\n",
    "# End information about the run\n",
    "print(f\"The used approach was {used_approach}.\")\n",
    "print(f\"Elapsed time: {elapsed_time_str}.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Saving the output in two file formats in dedicated files for only this current approach in the correct repository folder\n",
    "\n",
    "# Save the results to an Excel file\n",
    "excel_output_file_nltk = os.path.join(output_folder, 'sentiment_results_nltk.xlsx')\n",
    "df_nltk_3.to_excel(excel_output_file_nltk, index=False)\n",
    "\n",
    "# Save the results to a csv file with the same name\n",
    "csv_output_file_nltk = os.path.join(output_folder, 'sentiment_results_nltk.csv')\n",
    "df_nltk_3.to_csv(csv_output_file_nltk, index=False, encoding='utf-8', quoting=csv.QUOTE_ALL)\n",
    "\n",
    "# Print final info\n",
    "print(f\"Results saved as {csv_output_file_nltk} and {excel_output_file_nltk}.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Explorative Analysis of NLTK (VADER)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a histogram to visualize the distribution of sentiment scores\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(df_nltk_3['NLTK_Sentiment'], bins=20, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of NLTK Sentiment Scores')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add mean and standard deviation lines to the plot\n",
    "mean_score = np.mean(df_nltk_3['NLTK_Sentiment'])\n",
    "std_deviation = np.std(df_nltk_3['NLTK_Sentiment'])\n",
    "plt.axvline(x=mean_score, color='red', linestyle='dashed', linewidth=2, label='Mean')\n",
    "plt.axvline(x=mean_score + std_deviation, color='green', linestyle='dashed', linewidth=2, label='Mean + Std Dev')\n",
    "plt.axvline(x=mean_score - std_deviation, color='green', linestyle='dashed', linewidth=2, label='Mean - Std Dev')\n",
    "\n",
    "# Add a legend to the plot\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create subplots for the two countplots\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(8, 10))\n",
    "\n",
    "# Define the order of sentiment labels\n",
    "sentiment_order = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Create countplots for Evenly Separated Logic\n",
    "sns.countplot(data=df_nltk_3, x='NLTK_Evenly_Separated_Label', color='blue', order=sentiment_order, ax=axes[0])\n",
    "axes[0].set_xlabel('NLTK Evenly Separated Label')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of NLTK Evenly Separated Sentiment Labels')\n",
    "\n",
    "# Create countplots for Normal Distribution Logic\n",
    "sns.countplot(data=df_nltk_3, x='NLTK_Normal_Distribution_Label', color='orange', order=sentiment_order, ax=axes[1])\n",
    "axes[1].set_xlabel('NLTK Normal Distribution Label')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Distribution of NLTK Normal Distribution Sentiment Labels')\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merge Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Merge the two dataframes based on Row_Number\n",
    "merged_df = pd.merge(df_textblob_3, df_nltk_3, on='Row_Number', how='inner')\n",
    "\n",
    "# Select the common columns from one of the original dataframes (e.g., df_textblob)\n",
    "common_columns = ['Row_Number', 'Unternehmen', 'Newstyp', 'Quelle', 'Nearest_Date', 'Cleaned_Text', 'Stock_Value']\n",
    "\n",
    "# Merge the common columns with the merged sentiment columns\n",
    "df_combined = df_textblob_3[common_columns].merge(merged_df, on='Row_Number', how='inner')\n",
    "\n",
    "# Drop not needed, duplicated columns\n",
    "columns_to_drop = ['Unternehmen_x', 'Newstyp_x', 'Quelle_x', 'Nearest_Date_x', 'Cleaned_Text_x', 'Stock_Value_x',\n",
    "                   'Unternehmen_y', 'Newstyp_y', 'Quelle_y', 'Nearest_Date_y', 'Cleaned_Text_y', 'Stock_Value_y']\n",
    "df_combined = df_combined.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Display the merged dataframe\n",
    "print(df_combined.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Saving the output in two file formats in dedicated files for only this current approach in the correct repository folder\n",
    "\n",
    "# Save the results to an Excel file\n",
    "excel_output_file_combined = os.path.join(output_folder, 'sentiment_results_combined.xlsx')\n",
    "df_combined.to_excel(excel_output_file_combined, index=False)\n",
    "\n",
    "# Save the results to a csv file with the same name\n",
    "csv_output_file_combined = os.path.join(output_folder, 'sentiment_results_combined.csv')\n",
    "df_combined.to_csv(csv_output_file_combined, index=False, encoding='utf-8', quoting=csv.QUOTE_ALL)\n",
    "\n",
    "# Print final info\n",
    "print(f\"Results saved as {csv_output_file_combined} and {excel_output_file_combined}.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Analysing similarities in the labels\n",
    "same_labels_count = (df_combined['TextBlob_Evenly_Separated_Label'] == df_combined['NLTK_Evenly_Separated_Label']).sum()\n",
    "\n",
    "total_rows = len(df_combined)\n",
    "\n",
    "percentage_same_labels = (same_labels_count / total_rows) * 100\n",
    "\n",
    "print(f\"Percentage of rows where TextBlob and NLTK have the same Evenly Separated Label: {percentage_same_labels:.2f}%\")\n",
    "\n",
    "# Now for the normal distribution\n",
    "same_labels_count = (df_combined['TextBlob_Normal_Distribution_Label'] == df_combined['NLTK_Normal_Distribution_Label']).sum()\n",
    "\n",
    "total_rows = len(df_combined)\n",
    "\n",
    "percentage_same_labels = (same_labels_count / total_rows) * 100\n",
    "\n",
    "print(f\"Percentage of rows where TextBlob and NLTK have the same Normal_Distribution_Label: {percentage_same_labels:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
